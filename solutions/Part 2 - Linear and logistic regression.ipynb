{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gothic-gnome",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "Revision:\n",
    "\n",
    "- Selecting dependent/independent variables\n",
    "- Training a linear regression model\n",
    "- Outputting the loss\n",
    "- Outputting coefficients\n",
    "- Generating new predictions\n",
    "- Using linear regression model to impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stainless-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rball\\AppData\\Local\\Temp\\ipykernel_30672\\2356328574.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.Fare.fillna(df.Fare.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load your cleaned version of the titanic dataset\n",
    "# (if you don't already have a saved copy, do some basic cleaning and save a copy now)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('datasets/titanic.csv')\n",
    "df.Fare.fillna(df.Fare.median(), inplace=True)\n",
    "X = np.array(df.Fare).reshape(-1,1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-chuck",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dirty-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select age as your dependent variable, and select any other variables that you'd like as your independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-focus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model to train on this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-malawi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the loss of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-people",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the coefficient weights to see which features seem to be having the largest effect on the dependent variable\n",
    "#(according to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-radical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fake datapoint and generate a prediction from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-offering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider how this technique could be used for imputing missing values more accurately than using the median value\n",
    "# in some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a linear regression model to impute values for any of the continuous variables in the data in the previous uncleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "suffering-olympus",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-truck",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "- A model to make categorical predictions (either binary or multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bed6d8-f3b0-406d-ad7f-4e7dcba96e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>7.8900</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803   7.8900  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time select survived (a categorical feature) as the dependent variable using logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-bachelor",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "direct-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df[['Pclass','Parch','SibSp','Fare']])\n",
    "\n",
    "y = df['Survived']\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the loss of the model (will need research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunrise-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0cece3-2a2e-4553-8ea4-1fca363f1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1ec14a-7033-435c-9362-ee6253b8d4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617f75b-845d-48e9-a3e9-350bcda8f334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the coefficients of the model (the same as in linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acceptable-compiler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69062914,  0.25240073, -0.14479629,  0.0050644 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new datapoint and output a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "starting-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21794066, 0.60535794, 0.24425467, 0.52667258, 0.24437154,\n",
       "       0.24475357, 0.61639682, 0.22358694, 0.35241434, 0.38426009,\n",
       "       0.27339835, 0.58566902, 0.24437154, 0.52646725, 0.24418849,\n",
       "       0.40180043, 0.20604827, 0.39815416, 0.22736229, 0.24360086,\n",
       "       0.41403128, 0.39815416, 0.24435209, 0.59662354, 0.22358694,\n",
       "       0.52660929, 0.24360086, 0.83396319, 0.24421185, 0.24422737,\n",
       "       0.58710711, 0.69186941, 0.2440911 , 0.39512418, 0.61845117,\n",
       "       0.58180375, 0.24360478, 0.24437154, 0.20293317, 0.22140589,\n",
       "       0.21986736, 0.3734503 , 0.24422737, 0.52287891, 0.24421185,\n",
       "       0.24437154, 0.22514583, 0.2440911 , 0.20596376, 0.22718441,\n",
       "       0.21493692, 0.24413783, 0.61192734, 0.379394  , 0.68523124,\n",
       "       0.59662354, 0.39512418, 0.24360478, 0.50538554, 0.2402539 ,\n",
       "       0.24360478, 0.64948628, 0.62000852, 0.27729503, 0.58710711,\n",
       "       0.27193779, 0.39512418, 0.24447284, 0.23078628, 0.19539149,\n",
       "       0.39512418, 0.2402539 , 0.47333386, 0.2242232 , 0.29245073,\n",
       "       0.24399767, 0.24422737, 0.24437154, 0.54306051, 0.2485333 ,\n",
       "       0.24526104, 0.24573007, 0.24412615, 0.61067801, 0.39512418,\n",
       "       0.17891048, 0.40537129, 0.24437154, 0.83396319, 0.24437154,\n",
       "       0.24437154, 0.24418849, 0.59306445, 0.33061093, 0.24362419,\n",
       "       0.24437154, 0.59559224, 0.68673573, 0.47249845, 0.379394  ,\n",
       "       0.24422737, 0.24422737, 0.70170819, 0.24493701, 0.19480497,\n",
       "       0.24422737, 0.24399767, 0.24411447, 0.24422737, 0.23288009,\n",
       "       0.61656146, 0.2242232 , 0.24437154, 0.22017154, 0.25041394,\n",
       "       0.24425467, 0.2440911 , 0.3734503 , 0.84781622, 0.25244339,\n",
       "       0.40218758, 0.24437154, 0.38426009, 0.39815416, 0.70170819,\n",
       "       0.22140589, 0.2440911 , 0.24352314, 0.2791277 , 0.24336764,\n",
       "       0.24422737, 0.24343759, 0.22426355, 0.379394  , 0.39815416,\n",
       "       0.40063948, 0.70047073, 0.58315856, 0.24546425, 0.64856338,\n",
       "       0.35718201, 0.2440911 , 0.22545521, 0.24315788, 0.39633522,\n",
       "       0.45381252, 0.2441339 , 0.3142486 , 0.53928799, 0.39815416,\n",
       "       0.39757785, 0.59967776, 0.24437154, 0.35631526, 0.24368252,\n",
       "       0.68457546, 0.2440755 , 0.24437154, 0.24494479, 0.18679549,\n",
       "       0.30244312, 0.40149616, 0.24411447, 0.24494479, 0.21493692,\n",
       "       0.36334383, 0.67755816, 0.4592096 , 0.58490073, 0.29245073,\n",
       "       0.59418354, 0.20604827, 0.26783388, 0.24425467, 0.59075459,\n",
       "       0.26458991, 0.22747167, 0.58832406, 0.39815416, 0.23692215,\n",
       "       0.18679549, 0.40064458, 0.25255093, 0.42099759, 0.36510294,\n",
       "       0.61416407, 0.22514583, 0.58566902, 0.27219275, 0.24422737,\n",
       "       0.39815416, 0.39815416, 0.21846265, 0.44035525, 0.58710711,\n",
       "       0.72185261, 0.2440911 , 0.29428444, 0.2440911 , 0.39815416,\n",
       "       0.24573007, 0.18679549, 0.24292104, 0.24360086, 0.24437154,\n",
       "       0.29645396, 0.22545521, 0.25455186, 0.2440911 , 0.59112699,\n",
       "       0.24343759, 0.4079016 , 0.24362419, 0.39815416, 0.21837256,\n",
       "       0.65486727, 0.24425467, 0.38058716, 0.64519896, 0.39512418,\n",
       "       0.24437154, 0.39815416, 0.24437154, 0.24422737, 0.62776245,\n",
       "       0.2455893 , 0.39512418, 0.24362419, 0.39815416, 0.22747167,\n",
       "       0.62000852, 0.24411447, 0.3987611 , 0.25255093, 0.39512418,\n",
       "       0.24390427, 0.379394  , 0.53960254, 0.39512418, 0.39727465,\n",
       "       0.2242232 , 0.22514583, 0.39512418, 0.24350756, 0.24360086,\n",
       "       0.59335042, 0.24411447, 0.52478865, 0.64230665, 0.379394  ,\n",
       "       0.24362419, 0.26716822, 0.58566902, 0.22567638, 0.36297781,\n",
       "       0.35718201, 0.64856338, 0.65694296, 0.94301371, 0.47628677,\n",
       "       0.2440911 , 0.25255093, 0.67318233, 0.55271088, 0.2440911 ,\n",
       "       0.39512418, 0.21493692, 0.21839417, 0.77577737, 0.71064757,\n",
       "       0.59112699, 0.23692215, 0.46808277, 0.6489537 , 0.2440911 ,\n",
       "       0.61340449, 0.2440911 , 0.38248846, 0.20604827, 0.27698435,\n",
       "       0.2440911 , 0.24418849, 0.24573007, 0.24437154, 0.58499294,\n",
       "       0.24494479, 0.24573007, 0.24422737, 0.39815416, 0.2440911 ,\n",
       "       0.64815926, 0.62903871, 0.39800247, 0.24512045, 0.24422737,\n",
       "       0.58710711, 0.24360478, 0.79234928, 0.59051483, 0.84781622,\n",
       "       0.2440911 , 0.20726781, 0.23692215, 0.3973656 , 0.24437154,\n",
       "       0.79234928, 0.68420996, 0.64984245, 0.37701206, 0.62244573,\n",
       "       0.65311882, 0.85265909, 0.44035525, 0.24422737, 0.44066729,\n",
       "       0.24418849, 0.379394  , 0.39936835, 0.82511329, 0.73113646,\n",
       "       0.24362419, 0.24422737, 0.3973656 , 0.44410282, 0.18679549,\n",
       "       0.71064757, 0.24268054, 0.39815416, 0.27726334, 0.68084558,\n",
       "       0.20726781, 0.58806339, 0.77577737, 0.20293317, 0.67780238,\n",
       "       0.24422737, 0.59967776, 0.70946594, 0.24437154, 0.59662354,\n",
       "       0.44035525, 0.83396319, 0.39815416, 0.39815416, 0.39815416,\n",
       "       0.39815416, 0.39815416, 0.22567638, 0.27259425, 0.24494479,\n",
       "       0.24547203, 0.59601398, 0.26397447, 0.22718441, 0.24360086,\n",
       "       0.24573007, 0.67755816, 0.39815416, 0.24421185, 0.24421185,\n",
       "       0.4592096 , 0.38144809, 0.30068757, 0.24343759, 0.22514583,\n",
       "       0.24362419, 0.61014689, 0.24360478, 0.2440911 , 0.63705225,\n",
       "       0.5860385 , 0.21729034, 0.24437154, 0.71064757, 0.22358694,\n",
       "       0.61845117, 0.24362419, 0.85662688, 0.24061559, 0.24411447,\n",
       "       0.79639404, 0.35775885, 0.24425467, 0.58180375, 0.24422737,\n",
       "       0.47333386, 0.2402539 , 0.39815416, 0.24407167, 0.39694121,\n",
       "       0.76483326, 0.2441339 , 0.19480497, 0.65486727, 0.35887473,\n",
       "       0.2441339 , 0.24418849, 0.41403128, 0.39512418, 0.39772948,\n",
       "       0.24425467, 0.24437154, 0.22017154, 0.22545521, 0.24494479,\n",
       "       0.3734503 , 0.2440911 , 0.43132742, 0.24411447, 0.22747167,\n",
       "       0.24422737, 0.24325883, 0.62776245, 0.38248846, 0.24425467,\n",
       "       0.24437154, 0.44848301, 0.52289382, 0.39815416, 0.36760117,\n",
       "       0.24422737, 0.2440755 , 0.24420793, 0.27109055, 0.27694631,\n",
       "       0.24362419, 0.379394  , 0.41403128, 0.2440911 , 0.24437154,\n",
       "       0.58566902, 0.22567638, 0.379394  , 0.24350756, 0.58660146,\n",
       "       0.76483326, 0.3142486 , 0.52087981, 0.91746362, 0.39512418,\n",
       "       0.44066729, 0.24573007, 0.21839417, 0.39815416, 0.24443   ,\n",
       "       0.75602239, 0.46808277, 0.58566902, 0.24800355, 0.59051483,\n",
       "       0.50538554, 0.22911673, 0.58714296, 0.62670172, 0.24437154,\n",
       "       0.24422737, 0.58566902, 0.58163431, 0.39512418, 0.2440911 ,\n",
       "       0.58566902, 0.24437154, 0.60027457, 0.39815416, 0.24437154,\n",
       "       0.24343759, 0.38248846, 0.58566902, 0.24406774, 0.24800355,\n",
       "       0.24362419, 0.24494479, 0.50538554, 0.39911533, 0.24604701,\n",
       "       0.61656146, 0.3734503 , 0.21776445, 0.243877  , 0.29838528,\n",
       "       0.2402539 , 0.38248846, 0.24437154, 0.24581222, 0.62903871,\n",
       "       0.22747167, 0.62776245, 0.58953478, 0.24437154, 0.27259425,\n",
       "       0.22911673, 0.24362419, 0.59051483, 0.61356889, 0.24437154,\n",
       "       0.25041394, 0.6137748 , 0.25102445, 0.79234928, 0.2441339 ,\n",
       "       0.24494479, 0.2440911 , 0.24397824, 0.24581222, 0.65694296,\n",
       "       0.64984245, 0.53928799, 0.58566902, 0.25816024, 0.29245073,\n",
       "       0.2440911 , 0.24437154, 0.58534638, 0.59089318, 0.24385365,\n",
       "       0.59481937, 0.39512418, 0.25973946, 0.379394  , 0.24422737,\n",
       "       0.66488744, 0.24422737, 0.24360086, 0.68084558, 0.24360478,\n",
       "       0.2440911 , 0.39512418, 0.79163491, 0.24425467, 0.38747213,\n",
       "       0.44035525, 0.24360478, 0.26397447, 0.3654943 , 0.24494479,\n",
       "       0.53960254, 0.58566902, 0.67931131, 0.25045359, 0.72454491,\n",
       "       0.74573698, 0.25244339, 0.25244339, 0.379394  , 0.64698496,\n",
       "       0.58499294, 0.379394  , 0.39920132, 0.27726334, 0.45381252,\n",
       "       0.78210722, 0.41403128, 0.24416512, 0.24360086, 0.24411447,\n",
       "       0.58566902, 0.56645052, 0.79639404, 0.67318233, 0.22682894,\n",
       "       0.2440911 , 0.24422737, 0.3987611 , 0.24437154, 0.24437154,\n",
       "       0.20801772, 0.24422737, 0.48667983, 0.24360478, 0.24418849,\n",
       "       0.39512418, 0.54556041, 0.5854693 , 0.2440911 , 0.24437154,\n",
       "       0.25045359, 0.39815416, 0.58660146, 0.22422681, 0.24425467,\n",
       "       0.44535345, 0.70698626, 0.41403128, 0.60224759, 0.24499162,\n",
       "       0.75395362, 0.40058378, 0.67268074, 0.24437154, 0.24437154,\n",
       "       0.24350756, 0.6137748 , 0.24362419, 0.34851392, 0.379394  ,\n",
       "       0.28095716, 0.42265736, 0.23692215, 0.24360086, 0.58786487,\n",
       "       0.406259  , 0.24422737, 0.60500424, 0.24437154, 0.58566902,\n",
       "       0.22519001, 0.24422737, 0.59051483, 0.52287891, 0.72885585,\n",
       "       0.52646725, 0.24343759, 0.22514583, 0.2440911 , 0.24437154,\n",
       "       0.55235536, 0.27109055, 0.22567638, 0.42099759, 0.39512418,\n",
       "       0.2242232 , 0.58248649, 0.27243531, 0.24418849, 0.25197782,\n",
       "       0.59274272, 0.3973656 , 0.64712872, 0.24422737, 0.2440755 ,\n",
       "       0.58990239, 0.24344151, 0.59051483, 0.55271088, 0.27729503,\n",
       "       0.39815416, 0.24425467, 0.44066729, 0.57282062, 0.22567638,\n",
       "       0.24418849, 0.63705225, 0.27729503, 0.29245073, 0.24800355,\n",
       "       0.61192734, 0.24422737, 0.59662354, 0.24390427, 0.24390427,\n",
       "       0.24422737, 0.47249845, 0.24473017, 0.24416512, 0.24315788,\n",
       "       0.40218758, 0.24422737, 0.27219275, 0.39815416, 0.78416433,\n",
       "       0.64540332, 0.24360086, 0.58448568, 0.24385365, 0.21852387,\n",
       "       0.40218758, 0.39815416, 0.24411447, 0.24437154, 0.58180375,\n",
       "       0.45663839, 0.58180375, 0.39512418, 0.39815416, 0.38248846,\n",
       "       0.24411447, 0.24437154, 0.24605096, 0.60766318, 0.9551554 ,\n",
       "       0.24445338, 0.64570601, 0.24547203, 0.2402539 , 0.45663839,\n",
       "       0.52287891, 0.21493692, 0.24636028, 0.2441339 , 0.82263871,\n",
       "       0.58795174, 0.29958388, 0.29245073, 0.24360086, 0.58566902,\n",
       "       0.3987611 , 0.24437154, 0.2440755 , 0.70698626, 0.24399767,\n",
       "       0.77190711, 0.58534638, 0.30068757, 0.24408335, 0.21846265,\n",
       "       0.41403128, 0.3987611 , 0.58534638, 0.72693749, 0.27193779,\n",
       "       0.61356889, 0.58566902, 0.58180375, 0.2457144 , 0.39815416,\n",
       "       0.24399767, 0.79639404, 0.39512418, 0.25140551, 0.24411447,\n",
       "       0.48513604, 0.21777169, 0.39815416, 0.39815416, 0.58315856,\n",
       "       0.24494479, 0.30852252, 0.24407942, 0.379394  , 0.21852387,\n",
       "       0.78277771, 0.25455186, 0.38248846, 0.39815416, 0.39815416,\n",
       "       0.25197782, 0.40537129, 0.94301371, 0.24422737, 0.24422737,\n",
       "       0.58990239, 0.61447484, 0.85265909, 0.22567638, 0.24425467,\n",
       "       0.66347232, 0.27698435, 0.39815416, 0.58315856, 0.2440911 ,\n",
       "       0.43661446, 0.29858411, 0.24573007, 0.24422737, 0.55235536,\n",
       "       0.426056  , 0.2441339 , 0.39633522, 0.24437154, 0.65694296,\n",
       "       0.25045359, 0.24350756, 0.24360478, 0.76483326, 0.24411447,\n",
       "       0.61340449, 0.60161051, 0.2440911 , 0.23288009, 0.2446639 ,\n",
       "       0.24573007, 0.24418849, 0.39512418, 0.24360086, 0.56214889,\n",
       "       0.2440911 , 0.2440911 , 0.2485333 , 0.24407942, 0.82263871,\n",
       "       0.24360478, 0.58795174, 0.58990239, 0.33384111, 0.24343759,\n",
       "       0.24362419, 0.24385365, 0.20604827, 0.33061093, 0.64856338,\n",
       "       0.2440911 , 0.41403128, 0.18679549, 0.59075459, 0.24422737,\n",
       "       0.39815416, 0.58490589, 0.24496427, 0.24360478, 0.28095716,\n",
       "       0.39815416, 0.44066729, 0.76483326, 0.29440278, 0.24336764,\n",
       "       0.24411447, 0.55271088, 0.24411447, 0.39815416, 0.58315856,\n",
       "       0.24421961, 0.25973946, 0.39512418, 0.25244339, 0.24437154,\n",
       "       0.55271088, 0.24425467, 0.45413163, 0.24287839, 0.27729503,\n",
       "       0.68842273, 0.24494479, 0.55271088, 0.29858411, 0.21493692,\n",
       "       0.24334433, 0.29245073, 0.55310057, 0.2440911 , 0.64948628,\n",
       "       0.2242232 , 0.43132742, 0.24360478, 0.24418849, 0.24460541,\n",
       "       0.67707921, 0.24494479, 0.24437154, 0.29245073, 0.58953478,\n",
       "       0.24425467, 0.39512418, 0.59112699, 0.24286674, 0.24494479,\n",
       "       0.24390427, 0.18679549, 0.24422737, 0.48513604, 0.62670172,\n",
       "       0.25244339, 0.24411447, 0.27193779, 0.66006142, 0.379394  ,\n",
       "       0.2952802 , 0.76027454, 0.58566902, 0.4219205 , 0.24360478,\n",
       "       0.19976385, 0.36226312, 0.58490589, 0.18679549, 0.39815416,\n",
       "       0.39815416, 0.3650269 , 0.6147589 , 0.24573007, 0.26783388,\n",
       "       0.24422737, 0.64230665, 0.55896234, 0.24526104, 0.37701206,\n",
       "       0.24360086, 0.24605481, 0.24422737, 0.24422737, 0.70789398,\n",
       "       0.47628677, 0.24422737, 0.24668567, 0.39512418, 0.24343759,\n",
       "       0.55968306, 0.39815416, 0.58990239, 0.33384111, 0.58990239,\n",
       "       0.2440911 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-display",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-peripheral",
   "metadata": {},
   "source": [
    "Accuracy - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous model, and the documentation above to output the accuracy score for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monthly-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "selective-challenge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6879910213243546"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fresh-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879910213243546\n"
     ]
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(y)\n",
    "df_pred['y_pred'] = y_pred\n",
    "\n",
    "df_pred.columns = ['y_true','y_pred']\n",
    "\n",
    "pred_1_is_1 = df_pred.loc[(df_pred['y_true'] == 1) & (df_pred['y_pred'] == 1)]\n",
    "pred_1_is_0 = df_pred.loc[(df_pred['y_true'] == 0) & (df_pred['y_pred'] == 1)]\n",
    "pred_0_is_1 = df_pred.loc[(df_pred['y_true'] == 1) & (df_pred['y_pred'] == 0)]\n",
    "pred_0_is_0 = df_pred.loc[(df_pred['y_true'] == 0) & (df_pred['y_pred'] == 0)]\n",
    "\n",
    "print((len(pred_1_is_1) + len(pred_0_is_0))/len(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c187cd71-a724-4603-80f2-c2ee778ee0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999000999000999\n"
     ]
    }
   ],
   "source": [
    "neg = 100000\n",
    "pos = 100\n",
    "\n",
    "print(100000/(100000+100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-waterproof",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
